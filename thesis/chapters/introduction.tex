\chapter{Introduction}
\label{ch:introduction}
    \Outline{Background, relevance}

    \Fixme{Copied from proposal, adapt}
    \Draft{
      When writing a compiler for a programming language,
      an important consideration is the treatment of binders and variables.
      A well-known technique when using dependently typed programming languages such as Agda
      \cite{Norell2008Agda}
      is to define an intrinsically typed syntax tree,
      where expressions are scope- and type-correct by construction and admit a total evaluation function
      \cite{Augustsson1999WellTypedInterpreter}.
      This construction has featured in several papers, exploring
      basic operations like renaming and substitution
      \cite{Allais2018UniverseOfSyntaxes}
      as well as compilation to different target languages
      \cite[online supplementary material]{Pickard2021CalculatingDependentlyTypedCompilers}.

      At the same time, there are large classes of important transformations
      that have not yet received much attention in an intrinsically typed setting.
      Optimisations, for example, play a central role in practical compilers
      and establishing their correctness is often not trivial,
      with ample opportunity for binding-related mistakes
      \cite{SpectorZabusky2019EmbracingFormalizationGap}
      \cite{Maclaurin2022Foil}.
      Letting the type checker keep track of important invariants
      promises to remove common sources of bugs.
      A mechanised proof of semantics preservation can increase confidence further.

      In return for the correctness guarantees, some additional work is required.
      Program \emph{analysis} not only needs to identify optimisation opportunities,
      but potentially also provide a proof witness that the optimisation is safe,
      e.g. that some dead code is indeed unused.
      For the \emph{transformation} of the intrinsically typed program,
      the programmer then has to convince the type checker
      that type- and scope-correctness invariants are preserved,
      which can be cumbersome.
      The goal of this thesis is to understand these consequences better and make the following contributions:

      \begin{enumerate}
        \item collect and document program analyses and transformations that can be performed on simple expression languages with variable binders
        \item implement several of these transformations using intrinsically typed expressions in the dependently-typed programming language Agda
        \item provide machine-checked proofs of the correctness (preservation of semantics) of the implemented transformations
        \item attempt to apply relevant techniques from the literature, such as datatype-generic programming on syntax trees
        \item identify common patterns and try capturing them as reusable building blocks (e.g. as datatype-generic constructions)
      \end{enumerate}
    }

  \paragraph{Structure}
    Chapters \ref{ch:program-transformations} and \ref{ch:binding-representation}
    introduce the simple expression language we will work with
    and then give some background information on program analysis and transformation,
    as well as different binding representations and pitfalls.

    In chapter \ref{ch:de-bruijn} we start by
    showing a typical intrinsically typed de Bruijn representation of a simple expression language.
    We then explain thinnings and motivate their application to computing variable liveness.
    Equipped with these tools,
    we implement dead binding elimination and let-sinking,
    first on the standard de Bruijn representation,
    later on a syntax tree annotated with the results of live variable analysis.
    We prove that both versions of dead binding elimination preserve semantics.

    Chapter \ref{ch:co-de-bruijn} continues the development by showing that variable liveness information
    can serve as the main mechanism for representing bindings, as witnessed by
    McBride's co-de-Bruijn representation
    \cite{McBride2018EveryBodysGotToBeSomewhere}.
    After explaining how co-de-Bruijn terms work and can be constructed from de Bruijn terms,
    we again implement dead binding elimination and prove it correct.
    Finally, we manage to implement dead-binding elimination, but encounter several complications
    and struggle with the proof of correctness.

    In chapter \ref{ch:generic-co-de-bruijn}, we explain the basic ideas of syntax-generic programming
    as presented by Allais et al.
    \cite{Allais2018UniverseOfSyntaxes}
    and extend it with basic support for co-de-Bruijn representation.
    This allows us to generically convert between de Bruijn and co-de-Bruijn representation
    and perform dead binding elimination.
    \Fixme{Can be fleshed out a little bit once everything stabilised.}

  \paragraph{Contributions}
    Our main contributions are:
    \begin{itemize}
      \item an implementation of (strongly) live variable analysis resulting in annotated intrinsically typed syntax trees
      \item an implementation of dead binding elimination and let-sinking on intrinsically typed syntax trees of three different flavours: de Bruijn, annotated de Bruijn, and co-de-Bruijn
      \item proofs of correctness (preservation of semantics) for the implementations of dead binding elimination
      \item an incomplete proof of correctness for co-de-Bruijn let-sinking, with an explanation of the main challenges
      \item a generic interpretation of the syntax descriptions presented by Allais et al. \cite{Allais2018UniverseOfSyntaxes} into co-de-Bruijn terms
      \item syntax-generic conversion between de Bruijn and co-de-Bruijn terms
      \item a syntax-generic implementation of dead binding elimination on co-de-Bruijn terms
    \end{itemize}
    The source code is available online%
    \footnote{\url{https://git.science.uu.nl/m.h.heinzel/correct-optimisations}}.

  \paragraph{Ethics review}
    The Ethics and Privacy Quick Scan of the Utrecht University Research Institute of Information and Computing Sciences was conducted (see Appendix \ref{app:ethics-quick-scan}).
    It classified this research as low-risk with no fuller ethics review or privacy assessment required.
